{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d51f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "\n",
    "# Torch ML libraries\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Misc.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770f11ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model name\n",
    "#MODEL_NAME = 'bert-base-cased'\n",
    "MODEL_NAME = 'allenai/scibert_scivocab_uncased'\n",
    "\n",
    "\n",
    "# Build a BERT based tokenizer\n",
    "#tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efb7c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Sentiment Classifier class \n",
    "class SentimentClassifier(nn.Module):\n",
    "    \n",
    "    # Constructor class \n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    # Forward propagaion class\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=False\n",
    "        )\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7099cc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_names = ['negative', 'positive']\n",
    "# Create an instance of your model\n",
    "model = SentimentClassifier(len(class_names))\n",
    "model = model.to(device)\n",
    "\n",
    "# Load the model's state dictionary\n",
    "model_path = './models/sci_bert_best_model_state_1000.bin'  # Path to the saved model file\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bb91984",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = \"This well-written, clear paper presents the design of a mobile application to support the sharing of personal stories using templates that are contextually customized to prompt easy curation and sharing of stories. The design is grounded in a formative study that motivates the requirements. The resulting design responds to the findings of the formative study to present an app that allows users to quickly choose a template and customize it to create a visual story that can be shared a social website of the user's choice. For example, templates are pre-populated with images and prompt questions based on their theme, and the user can customize the image or add a new one, answer the questions or write something else. Some data is automatically populated (e.g. date) or made available (e.g. map of run). Then the user shares the combined image with friends. The initial prototype was populated with templates related to running (getting started to run, hard day, etc.) The application was deployed in a pair of deployment studies with real runnings for 4 weeks each. The participants all had an active running lifestyle. Rich field study data about the use of Yarn and the participant feedback including quotes were provided. Some interesting findings, such as visual templates constrain creativity (while providing other functions) were surprising and informative. The description sentences preformatted into the box were also not well subscribed as users preferred flexibility. Finally, there was an unexpected finding that Yarn is best used for personal notes rather than shared. Both the formative study and field study are clearly reported with extensive evidence of participant feedback. Overall, I liked this paper. The accompanying video was interesting. as were the supplied supplemental materials. The paper is a bit longer than necessary to tell the story, but there were no parts I felt were egregious as the longest sections included quite a few participant quotes which was helpful. The negative of this paper is the level of contribution in terms of what new, generalizable HCI is coming from the work. The results may not generalize to other story-sharing support systems. \"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3de2d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 160\n",
    "\n",
    "encoded_review = tokenizer.encode_plus(\n",
    "    review_text,\n",
    "    max_length=MAX_LEN,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "966f0ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review text: This well-written, clear paper presents the design of a mobile application to support the sharing of personal stories using templates that are contextually customized to prompt easy curation and sharing of stories. The design is grounded in a formative study that motivates the requirements. The resulting design responds to the findings of the formative study to present an app that allows users to quickly choose a template and customize it to create a visual story that can be shared a social website of the user's choice. For example, templates are pre-populated with images and prompt questions based on their theme, and the user can customize the image or add a new one, answer the questions or write something else. Some data is automatically populated (e.g. date) or made available (e.g. map of run). Then the user shares the combined image with friends. The initial prototype was populated with templates related to running (getting started to run, hard day, etc.) The application was deployed in a pair of deployment studies with real runnings for 4 weeks each. The participants all had an active running lifestyle. Rich field study data about the use of Yarn and the participant feedback including quotes were provided. Some interesting findings, such as visual templates constrain creativity (while providing other functions) were surprising and informative. The description sentences preformatted into the box were also not well subscribed as users preferred flexibility. Finally, there was an unexpected finding that Yarn is best used for personal notes rather than shared. Both the formative study and field study are clearly reported with extensive evidence of participant feedback. Overall, I liked this paper. The accompanying video was interesting. as were the supplied supplemental materials. The paper is a bit longer than necessary to tell the story, but there were no parts I felt were egregious as the longest sections included quite a few participant quotes which was helpful. The negative of this paper is the level of contribution in terms of what new, generalizable HCI is coming from the work. The results may not generalize to other story-sharing support systems. \n",
      "Sentiment  : positive\n"
     ]
    }
   ],
   "source": [
    "input_ids = encoded_review['input_ids'].to(device)\n",
    "attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "output = model(input_ids, attention_mask)\n",
    "_, prediction = torch.max(output, dim=1)\n",
    "\n",
    "print(f'Review text: {review_text}')\n",
    "print(f'Sentiment  : {class_names[prediction]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
